{"cells":[{"cell_type":"code","source":["%run ./Setup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Setup the connection","showTitle":true,"inputWidgets":{},"nuid":"e18d42df-78aa-4edb-8529-d2f5752f3d6c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.conf.set(\"spark.datasource.singlestore.ddlEndpoint\", cluster)\nspark.conf.set(\"spark.datasource.singlestore.user\", \"admin\")\nspark.conf.set(\"spark.datasource.singlestore.password\", password)\nspark.conf.set(\"spark.datasource.singlestore.disablePushdown\", \"false\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Set the SingleStore Connector variables","showTitle":true,"inputWidgets":{},"nuid":"1d89a410-871f-4491-8dc3-77aa8aaabb48"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["df = (spark.read\n      .format(\"singlestore\")\n      .load(\"weather.temperatures_all\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Create a Dataframe using the SingleStore Connector","showTitle":true,"inputWidgets":{},"nuid":"aeab620b-a899-4755-aa93-7b58da16b449"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["df.createOrReplaceTempView(\"temperatures\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Create a temporary Spark Table","showTitle":true,"inputWidgets":{},"nuid":"972e07bf-3679-47ab-8af5-e668b0edfff7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["def convert_to_c(f):\n  c = (f - 32) * (5 / 9)\n  return round(c, 2)\n\nspark.udf.register(\"convert_to_c\", convert_to_c)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Create and register a Python UDF","showTitle":true,"inputWidgets":{},"nuid":"2a0a2994-b328-48ad-a6bc-cdc01356212d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.sql(\n  \"SELECT Date, convert_to_c(Max) as Max_C, convert_to_c(Min) as Min_C FROM temperatures WHERE City = 'San Francisco'\"\n).explain()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"See all the stages of the Optimisation and Pushdown","showTitle":true,"inputWidgets":{},"nuid":"88986c4b-1ee4-4b1e-b717-a6b85a18370b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Using ```.explain()``` we can see the execution plan. The final plan shows a single projection on top of a scan.\n\nThe SingleStore Connector was able to Pushdown the following to SingleStore:<br/>\n```SELECT Date, ...```<br/>\nand<br/>\n```WHERE City = 'San Francisco'```<br/>\n\nEvaluation of the UDF on the fields <strong>Max</strong> and <strong>Min</strong> was left to Spark, since that is where the UDF lives."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Notes on .explain()","showTitle":true,"inputWidgets":{},"nuid":"db55664d-e559-4601-aa7a-b55d0adbea55"}}},{"cell_type":"code","source":["display(spark.sql(\n  \"SELECT Date, convert_to_c(Max) as Max_C, convert_to_c(Min) as Min_C FROM temperatures WHERE City = 'San Francisco'\"\n))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Plot \"Max\" and \"Min\" in Celsius for San Francisco","showTitle":true,"inputWidgets":{},"nuid":"54e466a5-22a1-4318-a475-ba2adb7802b1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Benefits of SingleStore Connector:\n- Implemented as a native Spark SQL plugin.\n- Accelerates ingest from Spark via compression.\n- Supports data loading and extraction from database tables and Spark Dataframes.\n- Integrates with the Catalyst query optimiser and supports robust SQL Pushdown.\n- Accelerates ML workloads."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Summary","showTitle":true,"inputWidgets":{},"nuid":"95c3d057-1c2a-4fb2-be97-883b630b6473"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Pushdown Example","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2018516943931014}},"nbformat":4,"nbformat_minor":0}
